{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, torch\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import multiprocessing as mp\n",
    "import neuropythy as ny\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import ipyvolume as ipv\n",
    "import pythreejs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_ids = [\n",
    "    \"sub-wlsubj001\", \"sub-wlsubj004\", \"sub-wlsubj006\", \"sub-wlsubj007\",\n",
    "    \"sub-wlsubj014\", \"sub-wlsubj019\", \"sub-wlsubj023\", \"sub-wlsubj042\",\n",
    "    \"sub-wlsubj045\", \"sub-wlsubj046\", \"sub-wlsubj055\", \"sub-wlsubj056\",\n",
    "    \"sub-wlsubj057\", \"sub-wlsubj062\", \"sub-wlsubj064\", \"sub-wlsubj067\",\n",
    "    \"sub-wlsubj071\", \"sub-wlsubj076\", \"sub-wlsubj079\", \"sub-wlsubj081\",\n",
    "    \"sub-wlsubj083\", \"sub-wlsubj084\", \"sub-wlsubj085\", \"sub-wlsubj086\",\n",
    "    \"sub-wlsubj087\", \"sub-wlsubj088\", \"sub-wlsubj090\", \"sub-wlsubj091\",\n",
    "    \"sub-wlsubj092\", \"sub-wlsubj095\", \"sub-wlsubj104\", \"sub-wlsubj105\",\n",
    "    \"sub-wlsubj109\", \"sub-wlsubj114\", \"sub-wlsubj115\", \"sub-wlsubj116\",\n",
    "    \"sub-wlsubj117\", \"sub-wlsubj118\", \"sub-wlsubj120\", \"sub-wlsubj122\",\n",
    "    \"sub-wlsubj126\"]\n",
    "participant_ids = np.array(participant_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_surf(pid, h, surface='white', as_fsaverage=True,\n",
    "              dataset_path='/data/openneuro/ds003787',\n",
    "              as_hemi=False):\n",
    "    \"Loads a subject's hemisphere from the NYU Retinotopy Dataset.\"\n",
    "    # Prepare some paths.\n",
    "    der_path = os.path.join(dataset_path, 'derivatives')\n",
    "    prf_path = os.path.join(der_path, 'prfanalyze-vista', pid, 'ses-nyu3t01')\n",
    "    roi_path = os.path.join(der_path, 'ROIs', pid)\n",
    "    sub_path = os.path.join(der_path, 'freesurfer', pid)\n",
    "    bay_path = os.path.join(der_path, 'bayesian_inference_maps', pid)\n",
    "    # Load the subject.\n",
    "    sub = ny.freesurfer_subject(sub_path, check_path=False)\n",
    "    # Load the hemisphere properties.\n",
    "    hem = sub.hemis[h]\n",
    "    srf = hem.surface(surface)\n",
    "    hem = hem.with_prop(\n",
    "        prf_x=ny.load(f'{prf_path}/{h}.x.mgz'),\n",
    "        prf_y=ny.load(f'{prf_path}/{h}.y.mgz'),\n",
    "        prf_cod=ny.load(f'{prf_path}/{h}.vexpl.mgz'),\n",
    "        visual_area=ny.load(f'{roi_path}/{h}.ROIs_V1-4.mgz'),\n",
    "        x=srf.coordinates[0],\n",
    "        y=srf.coordinates[1],\n",
    "        z=srf.coordinates[2],\n",
    "        inf_polar_angle=ny.load(f'{bay_path}/{h}.inferred_angle.mgz'),\n",
    "        inf_eccentricity=ny.load(f'{bay_path}/{h}.inferred_eccen.mgz'),\n",
    "        inf_visual_area=ny.load(f'{bay_path}/{h}.inferred_varea.mgz'))\n",
    "    if not as_fsaverage:\n",
    "        if as_hemi: return hem\n",
    "        return hem.surface(surface)\n",
    "    # Load the Freesurfeer Subject\n",
    "    fsaverage = ny.freesurfer_subject('fsaverage')\n",
    "    fshem = fsaverage.hemis[h]\n",
    "    # Interpolate the properties over to the fsaverage.\n",
    "    fs_props = hem.interpolate(fshem, hem.properties)\n",
    "    fshem = fshem.with_prop(fs_props)\n",
    "    fssrf = fshem.surface(surface)\n",
    "    fssrf = fssrf.copy(coordinates=[fs_props['x'], fs_props['y'], fs_props['z']])\n",
    "    (ang,ecc) = ny.as_retinotopy({'lon':fs_props['prf_x'], 'lat':-fs_props['prf_y']},\n",
    "                                 'visual')\n",
    "    fssrf = fssrf.with_prop(polar_angle=ang, eccentricity=ecc,\n",
    "                            cod=fs_props['prf_cod'])\n",
    "    return fssrf    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safesqrt(x):\n",
    "    ii = (x != 0)\n",
    "    y = x.clone()\n",
    "    y[ii] = torch.sqrt(x[ii])\n",
    "    return y\n",
    "def angmod(theta, hva=0.5, vma=0.5):\n",
    "    from numpy import pi\n",
    "    from torch import sin, cos, sign\n",
    "    hvpart = hva * cos(2 * theta)\n",
    "    thsin  = sin(theta)\n",
    "    ulpart = vma * sign(thsin) * thsin**2\n",
    "    return 1.0 + 0.5*(hvpart - ulpart)\n",
    "def vismodel(hem, label=1, max_eccen=9, hh91_c2=0.75, fsign=-1):\n",
    "    import torch\n",
    "    # Get the submesh we operate on.\n",
    "    h = hem.chirality\n",
    "    va = hem.prop('visual_area')\n",
    "    lbl = (va == label)\n",
    "    if ny.is_topo(hem):\n",
    "        mesh0 = hem.surface('midgray')\n",
    "    else:\n",
    "        mesh0 = hem\n",
    "    mesh = mesh0.submesh(lbl)\n",
    "    # Get the faces in the submesh.\n",
    "    (a,b,c) = np.array(mesh.tess.faces)\n",
    "    # And the surface areas.\n",
    "    cortex_sarea = torch.tensor(mesh.face_areas)\n",
    "    cortex_sarea_tot = torch.sum(cortex_sarea)\n",
    "    # And the edge lengths.\n",
    "    sxy = torch.tensor(mesh0.coordinates)\n",
    "    ab_surf_elen = safesqrt(torch.sum((sxy[:,b] - sxy[:,a])**2, axis=0))\n",
    "    bc_surf_elen = safesqrt(torch.sum((sxy[:,c] - sxy[:,b])**2, axis=0))\n",
    "    ca_surf_elen = safesqrt(torch.sum((sxy[:,a] - sxy[:,c])**2, axis=0))\n",
    "    # Calculate the H&H c1 value for this surface area.\n",
    "    c2_maxecc = torch.tensor(hh91_c2 + max_eccen)\n",
    "    den = np.pi * (torch.log(c2_maxecc / hh91_c2) - max_eccen / c2_maxecc)\n",
    "    c1 = safesqrt(cortex_sarea_tot / den)\n",
    "    # We also want to know what vertices are along the outer edge\n",
    "    (u,v) = mesh0.tess.edges\n",
    "    (uii,vii) = [np.where((va[u] == label) & (va[v] != label))[0],\n",
    "                 np.where((va[v] == label) & (va[u] != label))[0]]\n",
    "    ii_maxecc = [u[uii[va[v[uii]] == 0]], v[vii[va[u[vii]] == 0]]]\n",
    "    ii_hm     = [u[uii[va[v[uii]] != 0]], v[vii[va[u[vii]] != 0]]]\n",
    "    ii_maxecc = np.unique(np.concatenate(ii_maxecc))\n",
    "    ii_hm     = np.unique(np.concatenate(ii_hm))\n",
    "    # However, we want u and v to refer to mesh, not mesh0, below.\n",
    "    (u,v) = mesh.tess.edges\n",
    "    # Here's the basic model:\n",
    "    def _loss(xy, save_fsign=None):\n",
    "        # For each triangle, we need to know the cortical magnification.\n",
    "        # For this, we first calculate the visual surface area of each face.\n",
    "        (a_xy, b_xy, c_xy) = [xy[:,k] for k in (a, b, c)]\n",
    "        ab_xy = b_xy - a_xy\n",
    "        bc_xy = c_xy - b_xy\n",
    "        ca_xy = a_xy - c_xy\n",
    "        # We want to take the cross-product of ab x -ca; however, V1 has a\n",
    "        # negative field-sign, so we can ignore the minus-sign if we want a\n",
    "        # positive field-sign.\n",
    "        visual_fsign = fsign*torch.sign(ab_xy[0]*ca_xy[1] - ca_xy[0]*ab_xy[1])\n",
    "        if save_fsign is not None: save_fsign[0] = visual_fsign\n",
    "        (ablen, bclen, calen) = [safesqrt(torch.sum(uu**2, axis=0))\n",
    "                                 for uu in (ab_xy, bc_xy, ca_xy)]\n",
    "        s = (ablen + bclen + calen) / 2\n",
    "        visual_sarea = safesqrt(s*(s - ablen)*(s - bclen)*(s - calen))\n",
    "        visual_sarea = visual_fsign * visual_sarea\n",
    "        # Next predict the Horton and Hoyt (1991) cortical magnification for\n",
    "        # each triangle based on its average eccentricity and its cortical\n",
    "        # surface area.\n",
    "        face_xy = (a_xy + b_xy + c_xy) / 3\n",
    "        face_eccen = safesqrt(torch.sum(face_xy**2, axis=0))\n",
    "        face_theta = torch.atan2(face_xy[1], face_xy[0])\n",
    "        hh91_cmag = (c1 / (hh91_c2 + face_eccen))**2\n",
    "        hh91_cmag = hh91_cmag * angmod(face_theta)\n",
    "        hh91_visual_sarea = cortex_sarea / hh91_cmag\n",
    "        # The loss is the difference between the predicted and the measured\n",
    "        # visual surface area.\n",
    "        dd = visual_sarea - hh91_visual_sarea\n",
    "        ii = dd < 0\n",
    "        dd2 = dd**2\n",
    "        dd2[ii] -= dd[ii] + dd[ii]**3\n",
    "        dd = torch.mean(dd)\n",
    "        # Similar idea for the edges.\n",
    "        hh91_lincmag = safesqrt(hh91_cmag)\n",
    "        ee = ((ablen*visual_fsign - ab_surf_elen/hh91_lincmag)**2 +\n",
    "              (bclen*visual_fsign - bc_surf_elen/hh91_lincmag)**2 +\n",
    "              (calen*visual_fsign - ca_surf_elen/hh91_lincmag)**2)\n",
    "        ee = torch.mean(ee)\n",
    "        # We also add in the outer difference.\n",
    "        outer_ecc = safesqrt(torch.sum(xy[:,ii_maxecc]**2, axis=0))\n",
    "        outer_hm  = xy[0, ii_hm]\n",
    "        oo = torch.mean((outer_ecc - (max_eccen+2))**2) + torch.mean(outer_hm**2)\n",
    "        return (dd, ee, oo)\n",
    "    # Also, get the initial starting points.\n",
    "    (x0,y0) = ny.as_retinotopy(\n",
    "        ny.retinotopy_data(hem, 'inf_'),\n",
    "        'geographical')\n",
    "    if h == 'rh': x0 = -x0\n",
    "    x0 = torch.tensor(x0.astype(float))\n",
    "    y0 = torch.tensor(y0.astype(float))\n",
    "    xy0 = torch.vstack([x0[None,:], y0[None,:]])\n",
    "    xy0[:, ~lbl] = np.nan\n",
    "    # Also, get map-based starting points\n",
    "    fmap = ny.to_flatmap('occipital_pole', hem)\n",
    "    ii = np.isin(fmap.labels, mesh.labels)\n",
    "    tmp = np.array([fmap.coordinates[0,ii], -fmap.coordinates[1,ii]])\n",
    "    xy1 = torch.zeros_like(xy0)\n",
    "    xy1[:,mesh.labels] = torch.tensor(np.array(tmp))\n",
    "    return (_loss, mesh, xy0, xy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prfmodel_plan = [\n",
    "    dict(steps=1000, pw=1, ew=1, lr=0.20, lr_decay=0),\n",
    "    dict(steps=1000, pw=1, ew=1, lr=0.15, lr_decay=0),\n",
    "    dict(steps=1000, pw=1, ew=1, lr=0.10, lr_decay=0.01)]\n",
    "def calc_prfmodel(pid, h, plan=prfmodel_plan):\n",
    "    hem = load_surf(pid, h,\n",
    "                    as_fsaverage=False, as_hemi=True)\n",
    "    # Get the loss function and the initial PRF solutions.\n",
    "    (lossfn, mesh, xy0, xy1) = vismodel(hem)\n",
    "    # Here's what we minimize.\n",
    "    xy = xy0.clone().detach()\n",
    "    ii = torch.any(~torch.isfinite(xy[:,mesh.labels]), axis=0)\n",
    "    xy[:,mesh.labels[ii]] = 0\n",
    "    #xy[0] -= torch.min(xy[0])\n",
    "    xy = xy.requires_grad_(True)\n",
    "    for (roundno,plan) in enumerate(plan):\n",
    "        steps = plan.get('steps', 100)\n",
    "        lr = plan.get('lr', 0.1)\n",
    "        lr_decay = plan.get('lr_decay', 0)\n",
    "        ww = plan.get('pw', 1)\n",
    "        ew = plan.get('ew', 1)\n",
    "        opt = torch.optim.Adagrad([xy], lr=lr, lr_decay=lr_decay)\n",
    "        for step in range(steps):\n",
    "            def closure():\n",
    "                opt.zero_grad()\n",
    "                (dd,ee,oo) = lossfn(xy)\n",
    "                ll = dd if torch.isfinite(dd) else 1.0e10\n",
    "                if ew > 0: ll = ll + ee*ew\n",
    "                if ww > 0: ll = ll + oo*ww\n",
    "                ll.backward()\n",
    "                return ll\n",
    "            opt.step(closure)\n",
    "    return xy\n",
    "def save_prfmodel(flnm, pid, h):\n",
    "    if os.path.isfile(flnm): return flnm\n",
    "    xy = calc_prfmodel(pid, h)\n",
    "    xy = xy.detach().numpy()\n",
    "    return ny.save(flnm, xy.T)\n",
    "def load_prfmodel(pid, h):\n",
    "    flnm = os.path.join(\"/data/nyuretinotopy_morph/prfmodels\",\n",
    "                        f\"{h}.{pid}.mgz\")\n",
    "    if not os.path.isfile(flnm):\n",
    "        save_prfmodel(flnm, pid, h)\n",
    "    return ny.load(flnm)\n",
    "def ensure_prfmodels(pid):\n",
    "    a = load_prfmodel(pid, 'lh')\n",
    "    b = load_prfmodel(pid, 'rh')\n",
    "    return (a.shape, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_tr(x):\n",
    "    y = (1 - np.cos(np.pi*2*(x-0.25)))/2\n",
    "    y[x < 0.25] = 0\n",
    "    y[x > 0.75] = 1\n",
    "    return y\n",
    "frame_rate = 30\n",
    "step_duration = 2\n",
    "frames_per_step = frame_rate * step_duration\n",
    "step_t0 = np.arange(0, frames_per_step) / (frames_per_step - 1)\n",
    "step_t = cos_tr(step_t0)\n",
    "vfmesh = ny.vision.visual_field_mesh(max_eccentricity=9, resolution=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_vfield(pid):\n",
    "    hs = {}\n",
    "    cms = {}\n",
    "    for h in ['lh','rh']:\n",
    "        hem = load_surf(pid, h, as_fsaverage=False, as_hemi=True)\n",
    "        mdl = load_prfmodel(pid, h)\n",
    "        (x,y) = mdl.T\n",
    "        ii = np.isfinite(x) & np.isfinite(y)\n",
    "        vfm = hem.white_surface.submesh(ii)\n",
    "        # Adjust the coordnates.\n",
    "        vfm = vfm.copy(coordinates=mdl[vfm.labels])\n",
    "        hs[h] = vfm\n",
    "        # Calculate vmag.\n",
    "        cms[h] = ny.vision.areal_cmag(vfm, retinotopy='prf_')\n",
    "    # Sample properties over to the visual field mesh\n",
    "    ps = {}\n",
    "    for (h,m) in hs.items():\n",
    "        u = m.interpolate(vfmesh, ['prf_x','prf_y'])\n",
    "        u = dict(x=u[0], y=u[1], cmag=cms[h](*vfmesh.coordinates))\n",
    "        ps[h] = u\n",
    "    import warnings\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        ps = {k: np.nanmean([ps['lh'][k], ps['rh'][k]], axis=0)\n",
    "              for k in ps['lh'].keys()}\n",
    "        neis = vfmesh.tess.indexed_neighborhoods\n",
    "        (found,fillno) = (True, 0)\n",
    "        while found and fillno < 4:\n",
    "            found = False\n",
    "            fillno += 1\n",
    "            for (k,v) in ps.items():\n",
    "                ii = np.where(~np.isfinite(v))[0]\n",
    "                if len(ii) == 0: continue\n",
    "                found = True\n",
    "                v[ii] = [np.nanmean(v[list(neis[k])]) for k in ii]\n",
    "        #for (k,v) in ps.items():\n",
    "        #    ii = np.where(~np.isfinite(v))[0]\n",
    "        #    if len(ii) == 0: continue\n",
    "        #    v[ii] = 0\n",
    "        return np.array([ps['x'],ps['y'],ps['cmag']])\n",
    "def save_vfield(flnm, pid, overwrite=False):\n",
    "    if not overwrite and os.path.isfile(flnm): return flnm\n",
    "    xy = calc_vfield(pid)\n",
    "    return ny.save(flnm, xy)\n",
    "def load_vfield(pid, overwrite=False):\n",
    "    flnm = os.path.join(\"/data/nyuretinotopy_morph/prfmodels\",\n",
    "                        f\"{pid}_vfmesh.mgz\")\n",
    "    if overwrite or not os.path.isfile(flnm):\n",
    "        save_vfield(flnm, pid, overwrite=overwrite)\n",
    "    return ny.load(flnm)\n",
    "def ensure_vfield(pid):\n",
    "    try:\n",
    "        return load_vfield(pid).shape\n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot_vfield(x, y, ax):\n",
    "    ang = np.mod(90 - 180/np.pi*np.arctan2(y, x) + 180, 360) - 180\n",
    "    return ny.cortex_plot(vfmesh, {'polar_angle':ang},\n",
    "                          underlay='w', axes=ax)\n",
    "def _plot_cmag(cmag, ax):\n",
    "    cmag = np.array(cmag)\n",
    "    cmag[~np.isfinite(cmag)] = 1e-10\n",
    "    cmag = np.log2(cmag)\n",
    "    cm = 'hot'\n",
    "    return ny.cortex_plot(vfmesh, color=cmag, cmap=cm,\n",
    "                          vmin=np.log2(2.0), vmax=np.log2(1024.0),\n",
    "                          underlay='0.5', axes=ax)\n",
    "def save_vfframe(pid1, pid2, frame0, w=None, figsize=(2,2), dpi=240,\n",
    "                 overwrite=False):\n",
    "    (x1,y1,cmag1) = load_vfield(pid1)\n",
    "    (x2,y2,cmag2) = load_vfield(pid2)\n",
    "    if w is None:\n",
    "        w = np.linspace(0,1,frames_per_step)\n",
    "        w = cos_tr(w)\n",
    "    (fig,ax) = plt.subplots(1,1, figsize=figsize, dpi=dpi)\n",
    "    fig.subplots_adjust(0,0,1,1,0,0)\n",
    "    for (f,w) in enumerate(w):\n",
    "        if w == 0:   f = frame0\n",
    "        elif w == 1: f = frame0 + frames_per_step - 1\n",
    "        else:        f += frame0\n",
    "        flnm = os.path.join('/data/nyuretinotopy_morph/frames_model',\n",
    "                            'frame%05d.png' % (f,))\n",
    "        if not overwrite and os.path.isfile(flnm): continue\n",
    "        x = x1*(1-w) + x2*w\n",
    "        y = y1*(1-w) + y2*w\n",
    "        cmag = cmag1*(1-w) + cmag2*w\n",
    "        ax.clear()\n",
    "        #pp = _plot_vfield(x, y, ax)\n",
    "        pp = _plot_cmag(cmag, ax)\n",
    "        ax.set_xlim([-9.1,9.1])\n",
    "        ax.set_ylim([-9.1,9.1])\n",
    "        ax.axis('off')\n",
    "        # Save the figure.\n",
    "        plt.savefig(flnm, bbox_inches='tight')\n",
    "    return fig\n",
    "def ensure_vfframe(tup):\n",
    "    fig = save_vfframe(*tup, overwrite=True)\n",
    "    plt.close(fig)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 41\n",
      "12 of 41\n",
      "24 of 41\n",
      "36 of 41\n"
     ]
    }
   ],
   "source": [
    "njobs = len(participant_ids)\n",
    "nproc = 12\n",
    "\n",
    "for ii in range(0, njobs, nproc):\n",
    "    jj = min(njobs, ii + nproc)\n",
    "    print(ii, \"of\", njobs)\n",
    "    with mp.Pool(jj - ii + 1) as pool:\n",
    "        pool.map(ensure_vfield, participant_ids[ii:jj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 41\n",
      "12 of 41\n",
      "24 of 41\n",
      "36 of 41\n"
     ]
    }
   ],
   "source": [
    "nproc = 12\n",
    "\n",
    "pids = participant_ids\n",
    "jobs = [(pid1,pid2,ii*frames_per_step)\n",
    "        for (ii,(pid1,pid2)) in enumerate(zip(pids,np.roll(pids,-1)))]\n",
    "njobs = len(jobs)\n",
    "\n",
    "for ii in range(0, njobs, nproc):\n",
    "    jj = min(njobs, ii + nproc)\n",
    "    print(ii, \"of\", njobs)\n",
    "    with mp.Pool(jj - ii + 1) as pool:\n",
    "        pool.map(ensure_vfframe, jobs[ii:jj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postproc_frame(fno):\n",
    "    bp = '/data/nyuretinotopy_morph'\n",
    "    fl1 = os.path.join(bp, 'frames', 'frame%05d.png' % fno)\n",
    "    fl2 = os.path.join(bp, 'frames_model', 'frame%05d.png' % fno)\n",
    "    flo = os.path.join(bp, 'frames_final', 'frame%05d.png' % fno)\n",
    "    if os.path.isfile(flo): return flo\n",
    "    im1 = plt.imread(fl1)\n",
    "    im2 = plt.imread(fl2)\n",
    "    (r,c) = im2.shape[:2]\n",
    "    hc = int(c/2)\n",
    "    c0 = int(im1.shape[1]/2) - hc\n",
    "    subim = im1[1180:(1180+r),c0:(c0+c),:]\n",
    "    fixim = np.flip(im2[:,:,:3], axis=0)\n",
    "    ii = np.where(~np.all(fixim == 1, axis=2))\n",
    "    subim[ii] = fixim[ii]\n",
    "    return plt.imsave(flo, im1)\n",
    "def postproc_job(tup):\n",
    "    (i0,skip) = tup\n",
    "    for k in range(i0, 2460, skip):\n",
    "        postproc_frame(k)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fig,ax) = plt.subplots(1,1, figsize=(1,5), dpi=288)\n",
    "\n",
    "im = np.transpose([np.linspace(2,1024,300)]*30)\n",
    "ax.imshow(im,\n",
    "          cmap='hot',\n",
    "          vmin=2, vmax=1024)\n",
    "ax.invert_yaxis()\n",
    "ax.set_yticks([0,100,200,300])\n",
    "ax.set_yticklabels([2,16,128,1024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nproc = 16\n",
    "with mp.Pool(nproc) as pool:\n",
    "    pool.map(postproc_job, enumerate([nproc]*nproc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Noah's Python Environment",
   "language": "python",
   "name": "python-nben"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
